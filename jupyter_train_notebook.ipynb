{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vohoaidanh/ADOF/blob/exp%2Fbackbones/jupyter_train_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bsPZQKgE3tX"
      },
      "source": [
        "## AIGCDetectBenchmark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiHwX8vIN8xm"
      },
      "source": [
        "## Install requirement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zedAZuw9N8xo",
        "outputId": "84330a48-ccee-4f33-a0c5-064652c0a6e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['git', 'clone', 'https://github.com/vohoaidanh/ADOF.git'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#!git clone https://github.com/vohoaidanh/ADOF.git\n",
        "\n",
        "import subprocess\n",
        "# Clone với HTTPS + Personal Access Token\n",
        "#token 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\n",
        "repo_url = \"https://github.com/vohoaidanh/ADOF.git\"\n",
        "subprocess.run([\"git\", \"clone\", repo_url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lz8DowdAEXlV"
      },
      "outputs": [],
      "source": [
        "USED_COLAB = True\n",
        "ROOT_DIR = \"/workspace\"\n",
        "if USED_COLAB:\n",
        "    ROOT_DIR = \"/content\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "diL52UgAPQSZ",
        "outputId": "24d447ef-275d-4796-ef4e-ccc0a9e3c413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ADOF\n"
          ]
        }
      ],
      "source": [
        "%cd $ROOT_DIR/ADOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "faTIxJIbEXlW",
        "outputId": "3de5705b-a44e-458f-ab1f-91da45e71269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'exp/backbones' set up to track remote branch 'exp/backbones' from 'origin'.\n",
            "Switched to a new branch 'exp/backbones'\n"
          ]
        }
      ],
      "source": [
        "!git checkout exp/backbones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": true,
        "id": "jrYMet-VEXlW"
      },
      "outputs": [],
      "source": [
        "!pip install gdown -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yZtRWDeMing8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#!pip install -r requirements.txt\n",
        "#!pip install tensorboardX -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zETSn3yrN8xq",
        "scrolled": true,
        "outputId": "45d5aa63-4467-4362-8416-f03657e53976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "zip is already the newest version (3.0-12build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hReading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following NEW packages will be installed:\n",
            "  libgl1-mesa-glx\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 5,584 B of archives.\n",
            "After this operation, 74.8 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgl1-mesa-glx amd64 23.0.4-0ubuntu1~22.04.1 [5,584 B]\n",
            "Fetched 5,584 B in 0s (34.8 kB/s)\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.0/720.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Without google colab\n",
        "!apt-get install -y unzip -q\n",
        "!apt-get install -y zip -q\n",
        "!pip install tensorboardX -q\n",
        "!pip install regex -q\n",
        "!pip install imageio -q\n",
        "!pip install opencv-python -q\n",
        "!apt-get install -y libgl1-mesa-glx -q\n",
        "!pip install scikit-learn -q\n",
        "!pip install scikit-image -q\n",
        "!pip install ftfy -q\n",
        "!pip install natsort -q\n",
        "!pip install blobfile -q\n",
        "!pip install timm -q\n",
        "!pip install comet_ml -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LFupkEVNEXlX"
      },
      "outputs": [],
      "source": [
        "#Convert All images in datasets to jpeg (images should be to lim of transform\n",
        "#!python convert2jpg.py \"D:\\datasets\\datasets\" \"D:\\datasets\\biggan_jpg\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "byvmW6zjEXlX",
        "outputId": "aeecef1f-4996-4ef0-ba0f-de93eca2da57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z\n",
            "From (redirected): https://drive.google.com/uc?id=1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z&confirm=t&uuid=b05e9bff-9b18-4c92-bb3f-8045e8a3abf7\n",
            "To: /content/Progan_train.zip\n",
            "100%|██████████| 2.64G/2.64G [00:35<00:00, 74.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "#https://drive.google.com/file/d/1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z/view?usp=drive_link\n",
        "\n",
        "\n",
        "#Download Train, val set\n",
        "import gdown\n",
        "file_id = '1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z' #Progan train/val 4 class [car, cat, chair, horse] 13Gb\n",
        "#file_id = '1cyGbozooewAt6pNH9gw2_sDMM-Locqh2' #Progan train/val 4 class [car, cat, chair, horse]\n",
        "destination = ROOT_DIR + '/Progan_train.zip'  # Desired file name and extension\n",
        "# Construct the download URL\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "# Download the file\n",
        "gdown.download(url, destination, quiet=False)\n",
        "#Unzip\n",
        "!mkdir -p $ROOT_DIR/datasets/ForenSynths_train\n",
        "!unzip -q $destination -d $ROOT_DIR/datasets/ForenSynths_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OSQYAAj0EXlY",
        "outputId": "57b1411f-cfd7-4975-9478-158482949353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-02FPvdTaQFDMatEvXAeKLCmnwW6RLx4\n",
            "From (redirected): https://drive.google.com/uc?id=1-02FPvdTaQFDMatEvXAeKLCmnwW6RLx4&confirm=t&uuid=f859dfda-ad10-47d2-9178-56713b0a83aa\n",
            "To: /content/test.zip\n",
            "100%|██████████| 1.68G/1.68G [00:22<00:00, 73.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "#https://drive.google.com/file/d/1-02FPvdTaQFDMatEvXAeKLCmnwW6RLx4/view?usp=drive_link\n",
        "\n",
        "#Download Train, val set\n",
        "import gdown\n",
        "file_id = '1-02FPvdTaQFDMatEvXAeKLCmnwW6RLx4' #Progan train/val 4 class [car, cat, chair, horse] 13Gb\n",
        "#file_id = '1cyGbozooewAt6pNH9gw2_sDMM-Locqh2' #Progan train/val 4 class [car, cat, chair, horse]\n",
        "destination = ROOT_DIR + '/test.zip'  # Desired file name and extension\n",
        "\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "# Download the file\n",
        "gdown.download(url, destination, quiet=False)\n",
        "#Unzip\n",
        "!mkdir -p $ROOT_DIR/datasets/ForenSynths_train/test\n",
        "!unzip -q $destination -d $ROOT_DIR/datasets/ForenSynths_train/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zY128DjN8xt"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tTnMSRWN8xu",
        "outputId": "0d42bc7d-ccd4-4bef-e0fe-48fb9544d7c4",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "                     arch: res50                         \n",
            "                 backbone: highpass                      \t[default: resnet50]\n",
            "               batch_size: 64                            \n",
            "                    beta1: 0.9                           \n",
            "                blur_prob: 0                             \n",
            "                 blur_sig: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                class_bal: False                         \n",
            "                  classes: car,cat,chair,horse           \t[default: ]\n",
            "           continue_train: False                         \n",
            "                 cropSize: 224                           \n",
            "                 data_aug: False                         \n",
            "                 dataroot: /content/datasets/ForenSynths_train\t[default: ./dataset/]\n",
            "                delr_freq: 5                             \t[default: 20]\n",
            "          earlystop_epoch: 15                            \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                  isTrain: True                          \t[default: None]\n",
            "               jpg_method: cv2                           \n",
            "                 jpg_prob: 0                             \n",
            "                 jpg_qual: 75                            \n",
            "               last_epoch: -1                            \n",
            "                 loadSize: 256                           \n",
            "                loss_freq: 50                            \t[default: 400]\n",
            "                       lr: 0.0002                        \t[default: 0.0001]\n",
            "                     mode: binary                        \n",
            "                     name: highpass-50percent_cutoff2025_03_03_03_52_46\t[default: experiment_name]\n",
            "                new_optim: False                         \n",
            "                    niter: 30                            \t[default: 1000]\n",
            "                  no_flip: False                         \n",
            "             num_features: auto                          \n",
            "              num_threads: 2                             \t[default: 8]\n",
            "           old_checkpoint: None                          \n",
            "                    optim: adam                          \n",
            "           resize_or_crop: scale_and_crop                \n",
            "                rz_interp: bilinear                      \n",
            "          save_epoch_freq: 20                            \n",
            "         save_latest_freq: 2000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "              train_split: train                         \n",
            "                use_comet: True                          \t[default: False]\n",
            "                val_split: val                           \n",
            "----------------- End -------------------\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/danhvohoai2-gmail-com/adof/b72fecf35e9343d88e5920deaff718cf\u001b[0m\n",
            "\n",
            "train.py  --name  highpass-50percent_cutoff  --dataroot  /content/datasets/ForenSynths_train  --num_thread  2  --classes  car,cat,chair,horse  --batch_size  64  --delr_freq  5  --loss_freq  50  --lr  0.0002  --niter  30  --backbone  highpass  --gpu_ids  0  --use_comet\n",
            "*************************\n",
            "2025_03_03_03_52_48\n",
            "(0 progan      ) acc: 50.0000; ap: 49.5922; r_acc: 0.0000; f_acc: 1.0000\n",
            "(1 stylegan    ) acc: 50.0000; ap: 49.2630; r_acc: 0.0000; f_acc: 1.0000\n",
            "(2 stylegan2   ) acc: 50.0000; ap: 46.0630; r_acc: 0.0000; f_acc: 1.0000\n",
            "(3 biggan      ) acc: 50.0000; ap: 61.0418; r_acc: 0.0000; f_acc: 1.0000\n",
            "(4 cyclegan    ) acc: 50.0000; ap: 43.7216; r_acc: 0.0000; f_acc: 1.0000\n",
            "(5 stargan     ) acc: 50.0000; ap: 50.9210; r_acc: 0.0000; f_acc: 1.0000\n",
            "(6 gaugan      ) acc: 50.0000; ap: 45.2724; r_acc: 0.0000; f_acc: 1.0000\n",
            "(7 deepfake    ) acc: 50.0000; ap: 37.6157; r_acc: 0.0000; f_acc: 1.0000\n",
            "(8 Mean      ) acc: 50.0000; ap: 47.9363\n",
            "*************************\n",
            "2025_03_03_03_54_00\n",
            "cwd: /content/ADOF\n",
            "2025_03_03_03_54_28 Train loss: 0.6976011991500854 at step: 50 lr 0.0002\n",
            "2025_03_03_03_54_56 Train loss: 0.6647826433181763 at step: 100 lr 0.0002\n",
            "2025_03_03_03_55_23 Train loss: 0.5304925441741943 at step: 150 lr 0.0002\n",
            "2025_03_03_03_55_51 Train loss: 0.4105878472328186 at step: 200 lr 0.0002\n",
            "2025_03_03_03_56_18 Train loss: 0.34066882729530334 at step: 250 lr 0.0002\n",
            "2025_03_03_03_56_45 Train loss: 0.3158206343650818 at step: 300 lr 0.0002\n",
            "2025_03_03_03_57_13 Train loss: 0.25856813788414 at step: 350 lr 0.0002\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_0.pth\n",
            " Epoch 0 : 2025_03_03_03_54_00 --> 2025_03_03_03_57_27\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 0) acc: 0.884375; ap: 0.9845764805003006\n",
            "*************************\n",
            "2025_03_03_03_57_35\n",
            "(0 progan      ) acc: 84.4250; ap: 96.7690; r_acc: 0.9785; f_acc: 0.7100\n",
            "(1 stylegan    ) acc: 67.2500; ap: 78.8909; r_acc: 0.9517; f_acc: 0.3933\n",
            "(2 stylegan2   ) acc: 75.9375; ap: 90.4857; r_acc: 0.9575; f_acc: 0.5613\n",
            "(3 biggan      ) acc: 61.7500; ap: 75.3320; r_acc: 0.9600; f_acc: 0.2750\n",
            "(4 cyclegan    ) acc: 55.8019; ap: 69.8312; r_acc: 0.9802; f_acc: 0.1358\n",
            "(5 stargan     ) acc: 52.5000; ap: 57.6205; r_acc: 1.0000; f_acc: 0.0500\n",
            "(6 gaugan      ) acc: 48.2500; ap: 45.8631; r_acc: 0.9450; f_acc: 0.0200\n",
            "(7 deepfake    ) acc: 74.0000; ap: 93.4049; r_acc: 0.5700; f_acc: 0.9100\n",
            "(8 Mean      ) acc: 64.9893; ap: 76.0247\n",
            "*************************\n",
            "2025_03_03_03_58_46\n",
            "2025_03_03_03_59_00 Train loss: 0.24024595320224762 at step: 400 lr 0.0002\n",
            "2025_03_03_03_59_27 Train loss: 0.18194791674613953 at step: 450 lr 0.0002\n",
            "2025_03_03_03_59_55 Train loss: 0.16115301847457886 at step: 500 lr 0.0002\n",
            "2025_03_03_04_00_22 Train loss: 0.17471915483474731 at step: 550 lr 0.0002\n",
            "2025_03_03_04_00_50 Train loss: 0.11305814236402512 at step: 600 lr 0.0002\n",
            "2025_03_03_04_01_17 Train loss: 0.03719308227300644 at step: 650 lr 0.0002\n",
            "2025_03_03_04_01_45 Train loss: 0.04574247822165489 at step: 700 lr 0.0002\n",
            "2025_03_03_04_02_12 Train loss: 0.09920273721218109 at step: 750 lr 0.0002\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_1.pth\n",
            " Epoch 1 : 2025_03_03_03_58_46 --> 2025_03_03_04_02_12\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 1) acc: 0.95125; ap: 0.997083214630494\n",
            "*************************\n",
            "2025_03_03_04_02_19\n",
            "(0 progan      ) acc: 92.7500; ap: 99.0603; r_acc: 0.9920; f_acc: 0.8630\n",
            "(1 stylegan    ) acc: 70.2500; ap: 92.7332; r_acc: 0.9967; f_acc: 0.4083\n",
            "(2 stylegan2   ) acc: 66.1875; ap: 93.6125; r_acc: 0.9950; f_acc: 0.3287\n",
            "(3 biggan      ) acc: 70.2500; ap: 85.8222; r_acc: 0.9550; f_acc: 0.4500\n",
            "(4 cyclegan    ) acc: 56.6981; ap: 64.5288; r_acc: 0.9321; f_acc: 0.2019\n",
            "(5 stargan     ) acc: 50.5000; ap: 88.5458; r_acc: 1.0000; f_acc: 0.0100\n",
            "(6 gaugan      ) acc: 46.7500; ap: 44.9634; r_acc: 0.9000; f_acc: 0.0350\n",
            "(7 deepfake    ) acc: 65.2500; ap: 70.0972; r_acc: 0.5500; f_acc: 0.7550\n",
            "(8 Mean      ) acc: 64.8295; ap: 79.9204\n",
            "*************************\n",
            "2025_03_03_04_03_31\n",
            "2025_03_03_04_03_59 Train loss: 0.050294335931539536 at step: 800 lr 0.0002\n",
            "2025_03_03_04_04_26 Train loss: 0.07858413457870483 at step: 850 lr 0.0002\n",
            "2025_03_03_04_04_54 Train loss: 0.07218511402606964 at step: 900 lr 0.0002\n",
            "2025_03_03_04_05_21 Train loss: 0.11113139241933823 at step: 950 lr 0.0002\n",
            "2025_03_03_04_05_49 Train loss: 0.07612621784210205 at step: 1000 lr 0.0002\n",
            "2025_03_03_04_06_16 Train loss: 0.02576298452913761 at step: 1050 lr 0.0002\n",
            "2025_03_03_04_06_44 Train loss: 0.0238949004560709 at step: 1100 lr 0.0002\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_2.pth\n",
            " Epoch 2 : 2025_03_03_04_03_31 --> 2025_03_03_04_06_58\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 2) acc: 0.980625; ap: 0.9990653992762714\n",
            "*************************\n",
            "2025_03_03_04_07_06\n",
            "(0 progan      ) acc: 96.2125; ap: 99.4267; r_acc: 0.9500; f_acc: 0.9742\n",
            "(1 stylegan    ) acc: 89.0833; ap: 97.0303; r_acc: 0.9783; f_acc: 0.8033\n",
            "(2 stylegan2   ) acc: 88.6250; ap: 97.1433; r_acc: 0.9788; f_acc: 0.7937\n",
            "(3 biggan      ) acc: 82.7500; ap: 90.2451; r_acc: 0.7250; f_acc: 0.9300\n",
            "(4 cyclegan    ) acc: 62.0755; ap: 69.7932; r_acc: 0.5585; f_acc: 0.6830\n",
            "(5 stargan     ) acc: 90.5000; ap: 99.9562; r_acc: 1.0000; f_acc: 0.8100\n",
            "(6 gaugan      ) acc: 55.7500; ap: 52.8902; r_acc: 0.4850; f_acc: 0.6300\n",
            "(7 deepfake    ) acc: 65.7500; ap: 92.0358; r_acc: 0.3200; f_acc: 0.9950\n",
            "(8 Mean      ) acc: 78.8433; ap: 87.3151\n",
            "*************************\n",
            "2025_03_03_04_08_17\n",
            "2025_03_03_04_08_31 Train loss: 0.08151886612176895 at step: 1150 lr 0.0002\n",
            "2025_03_03_04_08_58 Train loss: 0.07634412497282028 at step: 1200 lr 0.0002\n",
            "2025_03_03_04_09_26 Train loss: 0.03126954287290573 at step: 1250 lr 0.0002\n",
            "2025_03_03_04_09_53 Train loss: 0.024810589849948883 at step: 1300 lr 0.0002\n",
            "2025_03_03_04_10_21 Train loss: 0.04875246435403824 at step: 1350 lr 0.0002\n",
            "2025_03_03_04_10_48 Train loss: 0.022062446922063828 at step: 1400 lr 0.0002\n",
            "2025_03_03_04_11_16 Train loss: 0.062041111290454865 at step: 1450 lr 0.0002\n",
            "2025_03_03_04_11_43 Train loss: 0.059608519077301025 at step: 1500 lr 0.0002\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_3.pth\n",
            " Epoch 3 : 2025_03_03_04_08_17 --> 2025_03_03_04_11_43\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 3) acc: 0.98125; ap: 0.9990154498712769\n",
            "*************************\n",
            "2025_03_03_04_11_50\n",
            "(0 progan      ) acc: 97.8750; ap: 99.8355; r_acc: 0.9690; f_acc: 0.9885\n",
            "(1 stylegan    ) acc: 85.3333; ap: 95.0835; r_acc: 0.9633; f_acc: 0.7433\n",
            "(2 stylegan2   ) acc: 90.1875; ap: 97.7320; r_acc: 0.9738; f_acc: 0.8300\n",
            "(3 biggan      ) acc: 87.0000; ap: 94.3841; r_acc: 0.8350; f_acc: 0.9050\n",
            "(4 cyclegan    ) acc: 66.0377; ap: 77.9264; r_acc: 0.6632; f_acc: 0.6575\n",
            "(5 stargan     ) acc: 81.5000; ap: 99.7435; r_acc: 1.0000; f_acc: 0.6300\n",
            "(6 gaugan      ) acc: 70.2500; ap: 72.6437; r_acc: 0.6850; f_acc: 0.7200\n",
            "(7 deepfake    ) acc: 75.5000; ap: 90.3733; r_acc: 0.5650; f_acc: 0.9450\n",
            "(8 Mean      ) acc: 81.7104; ap: 90.9652\n",
            "*************************\n",
            "2025_03_03_04_13_02\n",
            "2025_03_03_04_13_30 Train loss: 0.03981821984052658 at step: 1550 lr 0.0002\n",
            "2025_03_03_04_13_58 Train loss: 0.012709027156233788 at step: 1600 lr 0.0002\n",
            "2025_03_03_04_14_25 Train loss: 0.041704211384058 at step: 1650 lr 0.0002\n",
            "2025_03_03_04_14_53 Train loss: 0.07073493301868439 at step: 1700 lr 0.0002\n",
            "2025_03_03_04_15_20 Train loss: 0.00726501177996397 at step: 1750 lr 0.0002\n",
            "2025_03_03_04_15_47 Train loss: 0.0020566987805068493 at step: 1800 lr 0.0002\n",
            "2025_03_03_04_16_15 Train loss: 0.02081364206969738 at step: 1850 lr 0.0002\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_4.pth\n",
            " Epoch 4 : 2025_03_03_04_13_02 --> 2025_03_03_04_16_29\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 4) acc: 0.920625; ap: 0.9938504201454715\n",
            "*************************\n",
            "2025_03_03_04_16_36\n",
            "(0 progan      ) acc: 88.7500; ap: 98.5012; r_acc: 0.9972; f_acc: 0.7778\n",
            "(1 stylegan    ) acc: 82.0833; ap: 94.4739; r_acc: 0.9833; f_acc: 0.6583\n",
            "(2 stylegan2   ) acc: 81.5000; ap: 96.2802; r_acc: 0.9975; f_acc: 0.6325\n",
            "(3 biggan      ) acc: 79.2500; ap: 87.7477; r_acc: 0.8650; f_acc: 0.7200\n",
            "(4 cyclegan    ) acc: 73.6792; ap: 80.0579; r_acc: 0.8019; f_acc: 0.6717\n",
            "(5 stargan     ) acc: 95.7500; ap: 99.5168; r_acc: 0.9800; f_acc: 0.9350\n",
            "(6 gaugan      ) acc: 72.7500; ap: 82.9795; r_acc: 0.9250; f_acc: 0.5300\n",
            "(7 deepfake    ) acc: 56.5000; ap: 90.5326; r_acc: 0.1300; f_acc: 1.0000\n",
            "(8 Mean      ) acc: 78.7828; ap: 91.2612\n",
            "*************************\n",
            "2025_03_03_04_17_46\n",
            "2025_03_03_04_18_00 Train loss: 0.08408413082361221 at step: 1900 lr 0.0002\n",
            "2025_03_03_04_18_27 Train loss: 0.021887386217713356 at step: 1950 lr 0.0002\n",
            "2025_03_03_04_18_55 Train loss: 0.04952866956591606 at step: 2000 lr 0.0002\n",
            "2025_03_03_04_19_22 Train loss: 0.03133653849363327 at step: 2050 lr 0.0002\n",
            "2025_03_03_04_19_50 Train loss: 0.0014299824833869934 at step: 2100 lr 0.0002\n",
            "2025_03_03_04_20_17 Train loss: 0.005421735346317291 at step: 2150 lr 0.0002\n",
            "2025_03_03_04_20_45 Train loss: 0.02376970648765564 at step: 2200 lr 0.0002\n",
            "2025_03_03_04_21_12 Train loss: 0.007748255506157875 at step: 2250 lr 0.0002\n",
            "2025_03_03_04_21_12 changing lr at the end of epoch 5, iters 2250\n",
            "*************************\n",
            "Changing lr from 0.0002 to 0.00018\n",
            "*************************\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_5.pth\n",
            " Epoch 5 : 2025_03_03_04_17_46 --> 2025_03_03_04_21_12\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 5) acc: 0.984375; ap: 0.9996989300987\n",
            "*************************\n",
            "2025_03_03_04_21_20\n",
            "(0 progan      ) acc: 97.7250; ap: 99.9086; r_acc: 0.9577; f_acc: 0.9968\n",
            "(1 stylegan    ) acc: 86.2500; ap: 95.0477; r_acc: 0.9200; f_acc: 0.8050\n",
            "(2 stylegan2   ) acc: 92.7500; ap: 98.2444; r_acc: 0.9400; f_acc: 0.9150\n",
            "(3 biggan      ) acc: 86.5000; ap: 95.0026; r_acc: 0.7650; f_acc: 0.9650\n",
            "(4 cyclegan    ) acc: 64.7170; ap: 73.5517; r_acc: 0.5019; f_acc: 0.7925\n",
            "(5 stargan     ) acc: 83.7500; ap: 96.1173; r_acc: 0.9500; f_acc: 0.7250\n",
            "(6 gaugan      ) acc: 82.5000; ap: 87.3095; r_acc: 0.7650; f_acc: 0.8850\n",
            "(7 deepfake    ) acc: 67.2500; ap: 89.9268; r_acc: 0.3700; f_acc: 0.9750\n",
            "(8 Mean      ) acc: 82.6802; ap: 91.8886\n",
            "*************************\n",
            "2025_03_03_04_22_32\n",
            "2025_03_03_04_23_00 Train loss: 0.021591922268271446 at step: 2300 lr 0.00018\n",
            "2025_03_03_04_23_27 Train loss: 0.00355031481012702 at step: 2350 lr 0.00018\n",
            "2025_03_03_04_23_55 Train loss: 0.040331557393074036 at step: 2400 lr 0.00018\n",
            "2025_03_03_04_24_22 Train loss: 0.01820986159145832 at step: 2450 lr 0.00018\n",
            "2025_03_03_04_24_50 Train loss: 0.00593219930306077 at step: 2500 lr 0.00018\n",
            "2025_03_03_04_25_17 Train loss: 0.0027761661913245916 at step: 2550 lr 0.00018\n",
            "2025_03_03_04_25_45 Train loss: 0.022322844713926315 at step: 2600 lr 0.00018\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_6.pth\n",
            " Epoch 6 : 2025_03_03_04_22_32 --> 2025_03_03_04_25_58\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 6) acc: 0.98375; ap: 0.999606816883338\n",
            "*************************\n",
            "2025_03_03_04_26_05\n",
            "(0 progan      ) acc: 96.6250; ap: 99.8726; r_acc: 0.9972; f_acc: 0.9353\n",
            "(1 stylegan    ) acc: 79.8333; ap: 94.7054; r_acc: 0.9883; f_acc: 0.6083\n",
            "(2 stylegan2   ) acc: 81.5000; ap: 97.5662; r_acc: 0.9950; f_acc: 0.6350\n",
            "(3 biggan      ) acc: 81.2500; ap: 93.3596; r_acc: 0.9350; f_acc: 0.6900\n",
            "(4 cyclegan    ) acc: 70.0472; ap: 79.4931; r_acc: 0.8509; f_acc: 0.5500\n",
            "(5 stargan     ) acc: 73.5000; ap: 99.8109; r_acc: 1.0000; f_acc: 0.4700\n",
            "(6 gaugan      ) acc: 63.2500; ap: 86.8025; r_acc: 0.9800; f_acc: 0.2850\n",
            "(7 deepfake    ) acc: 68.2500; ap: 81.5291; r_acc: 0.4100; f_acc: 0.9550\n",
            "(8 Mean      ) acc: 76.7819; ap: 91.6424\n",
            "*************************\n",
            "2025_03_03_04_27_17\n",
            "2025_03_03_04_27_32 Train loss: 0.07825516909360886 at step: 2650 lr 0.00018\n",
            "2025_03_03_04_27_59 Train loss: 0.042528510093688965 at step: 2700 lr 0.00018\n",
            "2025_03_03_04_28_26 Train loss: 0.0024740765802562237 at step: 2750 lr 0.00018\n",
            "2025_03_03_04_28_54 Train loss: 0.007029399275779724 at step: 2800 lr 0.00018\n",
            "2025_03_03_04_29_22 Train loss: 0.002594428136944771 at step: 2850 lr 0.00018\n",
            "2025_03_03_04_29_49 Train loss: 0.001593854045495391 at step: 2900 lr 0.00018\n",
            "2025_03_03_04_30_16 Train loss: 0.0010206622537225485 at step: 2950 lr 0.00018\n",
            "2025_03_03_04_30_44 Train loss: 0.006822016090154648 at step: 3000 lr 0.00018\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_7.pth\n",
            " Epoch 7 : 2025_03_03_04_27_17 --> 2025_03_03_04_30_44\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 7) acc: 0.99625; ap: 0.9999783218026078\n",
            "*************************\n",
            "2025_03_03_04_30_52\n",
            "(0 progan      ) acc: 98.9875; ap: 99.9485; r_acc: 0.9880; f_acc: 0.9918\n",
            "(1 stylegan    ) acc: 85.8333; ap: 95.7481; r_acc: 0.9817; f_acc: 0.7350\n",
            "(2 stylegan2   ) acc: 92.8125; ap: 98.9900; r_acc: 0.9825; f_acc: 0.8738\n",
            "(3 biggan      ) acc: 89.7500; ap: 97.3809; r_acc: 0.8500; f_acc: 0.9450\n",
            "(4 cyclegan    ) acc: 62.9245; ap: 76.4568; r_acc: 0.5396; f_acc: 0.7189\n",
            "(5 stargan     ) acc: 79.5000; ap: 99.4401; r_acc: 1.0000; f_acc: 0.5900\n",
            "(6 gaugan      ) acc: 83.2500; ap: 88.6070; r_acc: 0.7500; f_acc: 0.9150\n",
            "(7 deepfake    ) acc: 76.0000; ap: 81.6988; r_acc: 0.6100; f_acc: 0.9100\n",
            "(8 Mean      ) acc: 83.6322; ap: 92.2838\n",
            "*************************\n",
            "2025_03_03_04_32_02\n",
            "2025_03_03_04_32_30 Train loss: 0.03123064897954464 at step: 3050 lr 0.00018\n",
            "2025_03_03_04_32_58 Train loss: 0.011022836901247501 at step: 3100 lr 0.00018\n",
            "2025_03_03_04_33_25 Train loss: 0.00867527537047863 at step: 3150 lr 0.00018\n",
            "2025_03_03_04_33_53 Train loss: 0.014796770177781582 at step: 3200 lr 0.00018\n",
            "2025_03_03_04_34_20 Train loss: 0.011390460655093193 at step: 3250 lr 0.00018\n",
            "2025_03_03_04_34_48 Train loss: 0.00218598754145205 at step: 3300 lr 0.00018\n",
            "2025_03_03_04_35_15 Train loss: 0.0170321986079216 at step: 3350 lr 0.00018\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_8.pth\n",
            " Epoch 8 : 2025_03_03_04_32_02 --> 2025_03_03_04_35_29\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 8) acc: 0.99125; ap: 0.9999533533591423\n",
            "*************************\n",
            "2025_03_03_04_35_36\n",
            "(0 progan      ) acc: 97.7875; ap: 99.9358; r_acc: 0.9990; f_acc: 0.9567\n",
            "(1 stylegan    ) acc: 82.0000; ap: 97.5845; r_acc: 0.9933; f_acc: 0.6467\n",
            "(2 stylegan2   ) acc: 79.7500; ap: 97.7776; r_acc: 0.9988; f_acc: 0.5962\n",
            "(3 biggan      ) acc: 93.0000; ap: 97.8533; r_acc: 0.9050; f_acc: 0.9550\n",
            "(4 cyclegan    ) acc: 76.0849; ap: 85.3999; r_acc: 0.7434; f_acc: 0.7783\n",
            "(5 stargan     ) acc: 74.2500; ap: 99.6502; r_acc: 1.0000; f_acc: 0.4850\n",
            "(6 gaugan      ) acc: 85.0000; ap: 91.5536; r_acc: 0.8300; f_acc: 0.8700\n",
            "(7 deepfake    ) acc: 72.0000; ap: 93.9562; r_acc: 0.4800; f_acc: 0.9600\n",
            "(8 Mean      ) acc: 82.4841; ap: 95.4639\n",
            "*************************\n",
            "2025_03_03_04_36_47\n",
            "2025_03_03_04_37_01 Train loss: 0.0008891214965842664 at step: 3400 lr 0.00018\n",
            "2025_03_03_04_37_29 Train loss: 0.0010804547928273678 at step: 3450 lr 0.00018\n",
            "2025_03_03_04_37_56 Train loss: 0.0011079914402216673 at step: 3500 lr 0.00018\n",
            "2025_03_03_04_38_24 Train loss: 0.0011650205124169588 at step: 3550 lr 0.00018\n",
            "2025_03_03_04_38_51 Train loss: 0.00022552561131305993 at step: 3600 lr 0.00018\n",
            "2025_03_03_04_39_19 Train loss: 0.0024573474656790495 at step: 3650 lr 0.00018\n",
            "2025_03_03_04_39_46 Train loss: 0.008654053322970867 at step: 3700 lr 0.00018\n",
            "2025_03_03_04_40_13 Train loss: 0.0005340316565707326 at step: 3750 lr 0.00018\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_9.pth\n",
            " Epoch 9 : 2025_03_03_04_36_47 --> 2025_03_03_04_40_14\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 9) acc: 0.99875; ap: 0.9999984394506867\n",
            "*************************\n",
            "2025_03_03_04_40_21\n",
            "(0 progan      ) acc: 98.7125; ap: 99.8152; r_acc: 0.9978; f_acc: 0.9765\n",
            "(1 stylegan    ) acc: 83.9167; ap: 97.3889; r_acc: 0.9933; f_acc: 0.6850\n",
            "(2 stylegan2   ) acc: 86.0625; ap: 98.4842; r_acc: 0.9950; f_acc: 0.7262\n",
            "(3 biggan      ) acc: 92.0000; ap: 98.3332; r_acc: 0.8700; f_acc: 0.9700\n",
            "(4 cyclegan    ) acc: 69.5755; ap: 80.2912; r_acc: 0.6123; f_acc: 0.7792\n",
            "(5 stargan     ) acc: 74.0000; ap: 99.3845; r_acc: 1.0000; f_acc: 0.4800\n",
            "(6 gaugan      ) acc: 87.2500; ap: 93.9051; r_acc: 0.7650; f_acc: 0.9800\n",
            "(7 deepfake    ) acc: 72.0000; ap: 88.6637; r_acc: 0.4900; f_acc: 0.9500\n",
            "(8 Mean      ) acc: 82.9396; ap: 94.5332\n",
            "*************************\n",
            "2025_03_03_04_41_31\n",
            "2025_03_03_04_41_59 Train loss: 0.008609127253293991 at step: 3800 lr 0.00018\n",
            "2025_03_03_04_42_27 Train loss: 0.028881307691335678 at step: 3850 lr 0.00018\n",
            "2025_03_03_04_42_54 Train loss: 0.024548068642616272 at step: 3900 lr 0.00018\n",
            "2025_03_03_04_43_22 Train loss: 0.0031560594215989113 at step: 3950 lr 0.00018\n",
            "2025_03_03_04_43_49 Train loss: 0.005395392421633005 at step: 4000 lr 0.00018\n",
            "2025_03_03_04_44_16 Train loss: 0.0022086328826844692 at step: 4050 lr 0.00018\n",
            "2025_03_03_04_44_44 Train loss: 0.0007915774476714432 at step: 4100 lr 0.00018\n",
            "2025_03_03_04_44_58 changing lr at the end of epoch 10, iters 4125\n",
            "*************************\n",
            "Changing lr from 0.00018 to 0.000162\n",
            "*************************\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_10.pth\n",
            " Epoch 10 : 2025_03_03_04_41_31 --> 2025_03_03_04_44_58\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 10) acc: 0.993125; ap: 0.9999609813882094\n",
            "*************************\n",
            "2025_03_03_04_45_05\n",
            "(0 progan      ) acc: 97.8750; ap: 99.7508; r_acc: 0.9968; f_acc: 0.9607\n",
            "(1 stylegan    ) acc: 80.5000; ap: 96.0313; r_acc: 0.9950; f_acc: 0.6150\n",
            "(2 stylegan2   ) acc: 83.8750; ap: 98.3303; r_acc: 0.9962; f_acc: 0.6813\n",
            "(3 biggan      ) acc: 88.5000; ap: 97.9556; r_acc: 0.7700; f_acc: 1.0000\n",
            "(4 cyclegan    ) acc: 69.8585; ap: 81.3080; r_acc: 0.5142; f_acc: 0.8830\n",
            "(5 stargan     ) acc: 87.5000; ap: 99.6157; r_acc: 1.0000; f_acc: 0.7500\n",
            "(6 gaugan      ) acc: 83.5000; ap: 96.6754; r_acc: 0.6700; f_acc: 1.0000\n",
            "(7 deepfake    ) acc: 72.0000; ap: 78.1299; r_acc: 0.4950; f_acc: 0.9450\n",
            "(8 Mean      ) acc: 82.9511; ap: 93.4746\n",
            "*************************\n",
            "2025_03_03_04_46_15\n",
            "2025_03_03_04_46_30 Train loss: 0.0012850105995312333 at step: 4150 lr 0.000162\n",
            "2025_03_03_04_46_57 Train loss: 0.0019639371894299984 at step: 4200 lr 0.000162\n",
            "2025_03_03_04_47_25 Train loss: 0.003584521822631359 at step: 4250 lr 0.000162\n",
            "2025_03_03_04_47_52 Train loss: 0.0018888856284320354 at step: 4300 lr 0.000162\n",
            "2025_03_03_04_48_20 Train loss: 0.004352574702352285 at step: 4350 lr 0.000162\n",
            "2025_03_03_04_48_48 Train loss: 0.0002644066989887506 at step: 4400 lr 0.000162\n",
            "2025_03_03_04_49_15 Train loss: 0.00041351717663928866 at step: 4450 lr 0.000162\n",
            "2025_03_03_04_49_43 Train loss: 0.004974644165486097 at step: 4500 lr 0.000162\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_11.pth\n",
            " Epoch 11 : 2025_03_03_04_46_15 --> 2025_03_03_04_49_43\n",
            "Saving model ./checkpoints/highpass-50percent_cutoff2025_03_03_03_52_46/model_epoch_last.pth\n",
            "(Val @ epoch 11) acc: 0.98625; ap: 0.9999449037674792\n",
            "*************************\n",
            "2025_03_03_04_49_51\n",
            "(0 progan      ) acc: 96.5375; ap: 99.9221; r_acc: 0.9990; f_acc: 0.9317\n",
            "(1 stylegan    ) acc: 79.0000; ap: 95.3380; r_acc: 0.9967; f_acc: 0.5833\n",
            "(2 stylegan2   ) acc: 79.0625; ap: 97.7350; r_acc: 0.9975; f_acc: 0.5837\n",
            "(3 biggan      ) acc: 89.7500; ap: 97.2965; r_acc: 0.9450; f_acc: 0.8500\n",
            "(4 cyclegan    ) acc: 74.7170; ap: 83.9558; r_acc: 0.8217; f_acc: 0.6726\n",
            "(5 stargan     ) acc: 74.5000; ap: 99.9726; r_acc: 1.0000; f_acc: 0.4900\n",
            "(6 gaugan      ) acc: 87.5000; ap: 96.6971; r_acc: 0.9500; f_acc: 0.8000\n",
            "(7 deepfake    ) acc: 71.2500; ap: 79.8321; r_acc: 0.4700; f_acc: 0.9550\n",
            "(8 Mean      ) acc: 81.5396; ap: 93.8437\n",
            "*************************\n",
            "2025_03_03_04_51_02\n",
            "2025_03_03_04_51_30 Train loss: 0.0009020013967528939 at step: 4550 lr 0.000162\n",
            "2025_03_03_04_51_57 Train loss: 0.0016633697086945176 at step: 4600 lr 0.000162\n",
            "2025_03_03_04_52_25 Train loss: 0.009395798668265343 at step: 4650 lr 0.000162\n",
            "2025_03_03_04_52_52 Train loss: 0.00045664655044674873 at step: 4700 lr 0.000162\n",
            "2025_03_03_04_53_20 Train loss: 0.0017600210849195719 at step: 4750 lr 0.000162\n",
            "2025_03_03_04_53_47 Train loss: 0.0005382848903536797 at step: 4800 lr 0.000162\n"
          ]
        }
      ],
      "source": [
        "#experiment-01-no-filter\n",
        "backbone = 'highpass'\n",
        "!find /content/datasets -type d -name \"*ipynb*\" -exec rm -r {} +\n",
        "!python train.py \\\n",
        "--name $backbone-50percent_cutoff \\\n",
        "--dataroot $ROOT_DIR/datasets/ForenSynths_train \\\n",
        "--num_thread 2 \\\n",
        "--classes car,cat,chair,horse --batch_size 64 --delr_freq 5 --loss_freq 50  --lr 0.0002 --niter 30 \\\n",
        "--backbone $backbone \\\n",
        "--gpu_ids 0 \\\n",
        "--use_comet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFlXRww3Pk8G"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4b69jN7HEXlZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EHqItrNnEXlZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ZiHwX8vIN8xm"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (Spyder)",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}