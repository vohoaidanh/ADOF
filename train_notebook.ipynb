{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bsPZQKgE3tX"
      },
      "source": [
        "## AIGCDetectBenchmark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiHwX8vIN8xm"
      },
      "source": [
        "## Install requirement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zedAZuw9N8xo",
        "outputId": "59bce0ad-15b8-44b1-bfed-a424ebcc4831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ADOF'...\n",
            "remote: Enumerating objects: 870, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 870 (delta 43), reused 49 (delta 41), pack-reused 817 (from 1)\u001b[K\n",
            "Receiving objects: 100% (870/870), 28.78 MiB | 15.32 MiB/s, done.\n",
            "Resolving deltas: 100% (572/572), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vohoaidanh/ADOF.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "diL52UgAPQSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840e0786-56de-428e-b853-4173e7fa49e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ADOF\n"
          ]
        }
      ],
      "source": [
        "%cd ADOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yZtRWDeMing8",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe90704-d6e7-4110-cc64-fca1bcbabd54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (11.3.0)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.23.0+cu126)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.2.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.2.0->-r requirements.txt (line 6)) (3.0.2)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install tensorboardX -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zETSn3yrN8xq",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Without google colab\n",
        "COLAB = True\n",
        "if not COLAB:\n",
        "  !pip install gdown -q\n",
        "  !apt-get install -y unzip -q\n",
        "  !apt-get install -y zip -q\n",
        "  !pip install tensorboardX -q\n",
        "  !pip install regex -q\n",
        "  !pip install imageio -q\n",
        "  !pip install opencv-python -q\n",
        "  !apt-get install -y libgl1-mesa-glx -q\n",
        "  !pip install scikit-learn -q\n",
        "  !pip install scikit-image -q\n",
        "  !pip install ftfy -q\n",
        "  !pip install natsort -q\n",
        "  !pip install blobfile -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFlXRww3Pk8G"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHqGlQRbQNE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e314d571-d97a-4338-c8c4-20597082a039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z\n",
            "From (redirected): https://drive.google.com/uc?id=1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z&confirm=t&uuid=6c860d9b-9fab-4829-b947-97540cd5c9ef\n",
            "To: /content/ADOF/progan_train.zip\n",
            "100%|██████████| 2.64G/2.64G [00:26<00:00, 98.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Download Train, val set\n",
        "# https://drive.google.com/file/d/1JW-4upuC3Tqq9awz8gnRWEf61NncC8JT/view?usp=drive_link    (Full train, val set)\n",
        "# https://drive.google.com/file/d/1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z/view?usp=drive_link     (Small tran, val set)\n",
        "import gdown\n",
        "DATASET_PATH = 'datasets'\n",
        "TRAIN_SET_PATH = 'ForenSynths_train'\n",
        "file_id = '1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z' #Progan train/val 4 class [car, cat, chair, horse]\n",
        "filename_train = 'progan_train.zip'  # Desired file name and extension\n",
        "# Construct the download URL\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "# Download the file\n",
        "gdown.download(url, filename_train, quiet=False)\n",
        "#Unzip\n",
        "!mkdir -p $DATASET_PATH/$TRAIN_SET_PATH\n",
        "!mkdir -p $DATASET_PATH/$TRAIN_SET_PATH/test\n",
        "!unzip -q $filename_train -d $DATASET_PATH/$TRAIN_SET_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YEJ2C7IoQ5co",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c80aedd-87b2-40a5-d1fa-c74e7b7ec731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-02FPvdTaQFDMatEvXAeKLCmnwW6RLx4\n",
            "From (redirected): https://drive.google.com/uc?id=1-02FPvdTaQFDMatEvXAeKLCmnwW6RLx4&confirm=t&uuid=8c039f27-2a43-45b3-b7e4-a856f0c5f5d6\n",
            "To: /content/ADOF/test_set.zip\n",
            "100%|██████████| 1.68G/1.68G [00:20<00:00, 83.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnZip 6.00 of 20 April 2009, by Debian. Original by Info-ZIP.\n",
            "\n",
            "Usage: unzip [-Z] [-opts[modifiers]] file[.zip] [list] [-x xlist] [-d exdir]\n",
            "  Default action is to extract files in list, except those in xlist, to exdir;\n",
            "  file[.zip] may be a wildcard.  -Z => ZipInfo mode (\"unzip -Z\" for usage).\n",
            "\n",
            "  -p  extract files to pipe, no messages     -l  list files (short format)\n",
            "  -f  freshen existing files, create none    -t  test compressed archive data\n",
            "  -u  update files, create if necessary      -z  display archive comment only\n",
            "  -v  list verbosely/show version info       -T  timestamp archive to latest\n",
            "  -x  exclude files that follow (in xlist)   -d  extract files into exdir\n",
            "modifiers:\n",
            "  -n  never overwrite existing files         -q  quiet mode (-qq => quieter)\n",
            "  -o  overwrite files WITHOUT prompting      -a  auto-convert any text files\n",
            "  -j  junk paths (do not make directories)   -aa treat ALL files as text\n",
            "  -U  use escapes for all non-ASCII Unicode  -UU ignore any Unicode fields\n",
            "  -C  match filenames case-insensitively     -L  make (some) names lowercase\n",
            "  -X  restore UID/GID info                   -V  retain VMS version numbers\n",
            "  -K  keep setuid/setgid/tacky permissions   -M  pipe through \"more\" pager\n",
            "  -O CHARSET  specify a character encoding for DOS, Windows and OS/2 archives\n",
            "  -I CHARSET  specify a character encoding for UNIX and other archives\n",
            "\n",
            "See \"unzip -hh\" or unzip.txt for more help.  Examples:\n",
            "  unzip data1 -x joe   => extract all files except joe from zipfile data1.zip\n",
            "  unzip -p foo | more  => send contents of foo.zip via pipe into program more\n",
            "  unzip -fo foo ReadMe => quietly replace existing ReadMe if archive file newer\n"
          ]
        }
      ],
      "source": [
        "#Download small Test set (this is a small testset just use for reference during training)\n",
        "\n",
        "import gdown\n",
        "file_id = '1-02FPvdTaQFDMatEvXAeKLCmnwW6RLx4' #test_set\n",
        "filename_test = 'test_set.zip'  # Desired file name and extension\n",
        "# Construct the download URL\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "# Download the file\n",
        "gdown.download(url, filename_test, quiet=False)\n",
        "#Unzip\n",
        "!unzip -q $filename_test -d $DATASET_PATH/$TRAIN_SET_PATH/test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q $filename_test -d $DATASET_PATH/$TRAIN_SET_PATH/test"
      ],
      "metadata": {
        "id": "V5GFzaVXZo3D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zY128DjN8xt"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tTnMSRWN8xu",
        "outputId": "e88e14e3-a0a1-426f-eea8-7b02bd1c3965",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "                     arch: res50                         \n",
            "               batch_size: 32                            \t[default: 64]\n",
            "                    beta1: 0.9                           \n",
            "                blur_prob: 0                             \n",
            "                 blur_sig: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                class_bal: False                         \n",
            "                  classes: car,cat,chair,horse           \t[default: ]\n",
            "           continue_train: False                         \n",
            "                 cropSize: 224                           \n",
            "                 data_aug: False                         \n",
            "                 dataroot: datasets/ForenSynths_train    \t[default: ./dataset/]\n",
            "                delr_freq: 5                             \t[default: 20]\n",
            "          earlystop_epoch: 15                            \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                  isTrain: True                          \t[default: None]\n",
            "               jpg_method: cv2                           \n",
            "                 jpg_prob: 0                             \n",
            "                 jpg_qual: 75                            \n",
            "               last_epoch: -1                            \n",
            "                 loadSize: 256                           \n",
            "                loss_freq: 400                           \n",
            "                       lr: 0.0002                        \t[default: 0.0001]\n",
            "                     mode: binary                        \n",
            "                     name: adof-progan-4class-2025_07_12_02_58_48\t[default: experiment_name]\n",
            "                new_optim: False                         \n",
            "                    niter: 30                            \t[default: 1000]\n",
            "                  no_flip: False                         \n",
            "              num_threads: 2                             \t[default: 8]\n",
            "                    optim: adam                          \n",
            "           resize_or_crop: scale_and_crop                \n",
            "                rz_interp: bilinear                      \n",
            "          save_epoch_freq: 20                            \n",
            "         save_latest_freq: 2000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "              train_split: train                         \n",
            "                val_split: val                           \n",
            "----------------- End -------------------\n",
            "train.py  --name  adof-progan-4class-  --dataroot  datasets/ForenSynths_train  --num_thread  2  --classes  car,cat,chair,horse  --batch_size  32  --delr_freq  5  --lr  0.0002  --niter  30\n",
            "*************************\n",
            "2025_07_12_02_58_49\n",
            "(0 progan      ) acc: 50.0; ap: 51.8; r_acc: 1.0; f_acc: 0.0\n",
            "(1 stylegan    ) acc: 50.0; ap: 55.3; r_acc: 1.0; f_acc: 0.0\n",
            "(2 stylegan2   ) acc: 50.0; ap: 64.0; r_acc: 1.0; f_acc: 0.0\n",
            "(3 biggan      ) acc: 50.0; ap: 52.6; r_acc: 1.0; f_acc: 0.0\n",
            "(4 cyclegan    ) acc: 50.0; ap: 43.0; r_acc: 1.0; f_acc: 0.0\n",
            "(5 stargan     ) acc: 50.0; ap: 39.8; r_acc: 1.0; f_acc: 0.0\n",
            "(6 gaugan      ) acc: 50.0; ap: 37.3; r_acc: 1.0; f_acc: 0.0\n",
            "(7 deepfake    ) acc: 50.0; ap: 35.0; r_acc: 1.0; f_acc: 0.0\n",
            "(8 Mean      ) acc: 50.0; ap: 47.4\n",
            "*************************\n",
            "2025_07_12_02_59_57\n",
            "cwd: /content/ADOF\n",
            "2025_07_12_03_01_45 Train loss: 0.31975826621055603 at step: 400 lr 0.0002\n",
            "Saving model ./checkpoints/adof-progan-4class-2025_07_12_02_58_48/model_epoch_0.pth\n",
            "(Val @ epoch 0) acc: 0.89625; ap: 0.9879920365309278\n",
            "*************************\n",
            "2025_07_12_03_03_32\n",
            "(0 progan      ) acc: 89.6; ap: 98.7; r_acc: 1.0; f_acc: 0.8\n",
            "(1 stylegan    ) acc: 86.8; ap: 99.3; r_acc: 1.0; f_acc: 0.7\n",
            "(2 stylegan2   ) acc: 92.2; ap: 99.7; r_acc: 1.0; f_acc: 0.8\n",
            "(3 biggan      ) acc: 74.8; ap: 86.9; r_acc: 0.9; f_acc: 0.6\n",
            "(4 cyclegan    ) acc: 62.4; ap: 84.3; r_acc: 0.9; f_acc: 0.3\n",
            "(5 stargan     ) acc: 75.8; ap: 99.9; r_acc: 1.0; f_acc: 0.5\n",
            "(6 gaugan      ) acc: 54.2; ap: 64.1; r_acc: 0.8; f_acc: 0.2\n",
            "(7 deepfake    ) acc: 52.2; ap: 88.8; r_acc: 1.0; f_acc: 0.0\n",
            "(8 Mean      ) acc: 73.5; ap: 90.2\n",
            "*************************\n",
            "2025_07_12_03_04_46\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ADOF/train.py\", line 102, in <module>\n",
            "    model.optimize_parameters()\n",
            "  File \"/content/ADOF/networks/trainer.py\", line 64, in optimize_parameters\n",
            "    self.loss.backward()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "#experiment-01-no-filter\n",
        "!find $DATASET_PATH -type d -name \"*ipynb*\" -exec rm -r {} +\n",
        "!python train.py \\\n",
        "--name adof-progan-4class- \\\n",
        "--dataroot $DATASET_PATH/$TRAIN_SET_PATH \\\n",
        "--num_thread 2 \\\n",
        "--classes car,cat,chair,horse --batch_size 32 --delr_freq 5 --lr 0.0002 --niter 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW0ofv3qTkZa"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x download_dataset.sh\n",
        "!sed -i 's/\\r$//' download_dataset.sh\n",
        "!./download_dataset.sh"
      ],
      "metadata": {
        "id": "saqC-9xUlXwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wD2QXOfFTjZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e21568f-19a5-4839-e39b-dcd8977c7399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model_path ./weights/ADOF_model_epoch_9.pth\n",
            "=================================\n",
            "           ForenSynths\n",
            "=================================\n",
            "2025_09_10_16_24_58\n",
            "(0 stylegan2   ) acc: 99.4; ap: 100.0; r_acc: 1.0; f_acc: 1.0\n",
            "(1 progan      ) acc: 99.8; ap: 100.0; r_acc: 1.0; f_acc: 1.0\n",
            "(2 gaugan      ) acc: 71.0; ap: 81.4; r_acc: 0.5; f_acc: 0.9\n",
            "(3 cyclegan    ) acc: 85.6; ap: 94.1; r_acc: 0.9; f_acc: 0.8\n",
            "(4 stargan     ) acc: 96.8; ap: 100.0; r_acc: 0.9; f_acc: 1.0\n",
            "(5 deepfake    ) acc: 85.0; ap: 92.8; r_acc: 0.9; f_acc: 0.8\n",
            "(6 stylegan    ) acc: 99.8; ap: 100.0; r_acc: 1.0; f_acc: 1.0\n",
            "(7 biggan      ) acc: 80.0; ap: 91.5; r_acc: 0.6; f_acc: 1.0\n",
            "(8 Mean      ) acc: 89.7; ap: 95.0\n",
            "*************************\n"
          ]
        }
      ],
      "source": [
        "# You should update the test set directory in the \"test.py\" file.\n",
        "!find $DATASET_PATH -type d -name \"*ipynb*\" -exec rm -r {} +\n",
        "!python test.py \\\n",
        "--model_path ./weights/ADOF_model_epoch_9.pth  \\\n",
        "--num_thread 2 \\\n",
        "--batch_size 32"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# Link folder dạng \"uc?id=FOLDER_ID&export=download\"\n",
        "folder_id = \"1HdoWolRAia6QvUDr02lPX684XCSqEd71\"\n",
        "url = f\"https://drive.google.com/uc?id={folder_id}&export=download\"\n",
        "output = \"Trainable.zip\"\n",
        "\n",
        "gdown.download(url, output, quiet=False)\n"
      ],
      "metadata": {
        "id": "YZeID39adSgD",
        "outputId": "21ea7f1a-ac58-4f83-997c-03cf64c62651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1HdoWolRAia6QvUDr02lPX684XCSqEd71&export=download\n\nbut Gdown can't. Please check connections and permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         raise FileURLRetrievalError(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;34m\"Cannot retrieve the public link of the file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Cannot retrieve the public link of the file. You may need to change the permission to 'Anyone with the link', or have had many accesses. Check FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1374060648.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Trainable.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1HdoWolRAia6QvUDr02lPX684XCSqEd71&export=download\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}