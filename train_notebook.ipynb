{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bsPZQKgE3tX"
      },
      "source": [
        "## AIGCDetectBenchmark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiHwX8vIN8xm"
      },
      "source": [
        "## Install requirement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zedAZuw9N8xo",
        "outputId": "5adf1b56-db31-4ff2-8128-febdd8200534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ADOF'...\n",
            "remote: Enumerating objects: 850, done.\u001b[K\n",
            "remote: Counting objects: 100% (364/364), done.\u001b[K\n",
            "remote: Compressing objects: 100% (205/205), done.\u001b[K\n",
            "remote: Total 850 (delta 227), reused 261 (delta 143), pack-reused 486 (from 1)\u001b[K\n",
            "Receiving objects: 100% (850/850), 28.82 MiB | 20.77 MiB/s, done.\n",
            "Resolving deltas: 100% (521/521), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vohoaidanh/ADOF.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "diL52UgAPQSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8056e6e7-b350-4b66-f3c4-ef8b37197a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ADOF\n"
          ]
        }
      ],
      "source": [
        "%cd ADOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yZtRWDeMing8",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638b1c00-1239-4d49-97cd-996504cf025b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (11.2.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.21.0+cu124)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.2.0->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.2.0->-r requirements.txt (line 6)) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install tensorboardX -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zETSn3yrN8xq",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Without google colab\n",
        "COLAB = True\n",
        "if not COLAB:\n",
        "  !pip install gdown -q\n",
        "  !apt-get install -y unzip -q\n",
        "  !apt-get install -y zip -q\n",
        "  !pip install tensorboardX -q\n",
        "  !pip install regex -q\n",
        "  !pip install imageio -q\n",
        "  !pip install opencv-python -q\n",
        "  !apt-get install -y libgl1-mesa-glx -q\n",
        "  !pip install scikit-learn -q\n",
        "  !pip install scikit-image -q\n",
        "  !pip install ftfy -q\n",
        "  !pip install natsort -q\n",
        "  !pip install blobfile -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFlXRww3Pk8G"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MHqGlQRbQNE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e314d571-d97a-4338-c8c4-20597082a039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z\n",
            "From (redirected): https://drive.google.com/uc?id=1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z&confirm=t&uuid=6c860d9b-9fab-4829-b947-97540cd5c9ef\n",
            "To: /content/ADOF/progan_train.zip\n",
            "100%|██████████| 2.64G/2.64G [00:26<00:00, 98.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Download Train, val set\n",
        "# https://drive.google.com/file/d/1JW-4upuC3Tqq9awz8gnRWEf61NncC8JT/view?usp=drive_link    (Full train, val set)\n",
        "# https://drive.google.com/file/d/1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z/view?usp=drive_link     (Small tran, val set)\n",
        "import gdown\n",
        "DATASET_PATH = 'datasets'\n",
        "TRAIN_SET_PATH = 'ForenSynths_train'\n",
        "file_id = '1JLdFyM7JnaUa8y4wBOwNGs3rn4qKH58Z' #Progan train/val 4 class [car, cat, chair, horse]\n",
        "filename_train = 'progan_train.zip'  # Desired file name and extension\n",
        "# Construct the download URL\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "# Download the file\n",
        "gdown.download(url, filename_train, quiet=False)\n",
        "#Unzip\n",
        "!mkdir -p $DATASET_PATH/$TRAIN_SET_PATH\n",
        "!mkdir -p $DATASET_PATH/$TRAIN_SET_PATH/test\n",
        "!unzip -q $filename_train -d $DATASET_PATH/$TRAIN_SET_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YEJ2C7IoQ5co",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d3ef79-fc33-43a3-a99e-3f5797deffab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-02FPvdTaQFDMatEvXAeKLCmnwW6RLx4\n",
            "From (redirected): https://drive.google.com/uc?id=1-02FPvdTaQFDMatEvXAeKLCmnwW6RLx4&confirm=t&uuid=1e7da106-ee37-4217-ba48-735669beda46\n",
            "To: /content/ADOF/test_set.zip\n",
            "100%|██████████| 1.68G/1.68G [00:18<00:00, 89.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnZip 6.00 of 20 April 2009, by Debian. Original by Info-ZIP.\n",
            "\n",
            "Usage: unzip [-Z] [-opts[modifiers]] file[.zip] [list] [-x xlist] [-d exdir]\n",
            "  Default action is to extract files in list, except those in xlist, to exdir;\n",
            "  file[.zip] may be a wildcard.  -Z => ZipInfo mode (\"unzip -Z\" for usage).\n",
            "\n",
            "  -p  extract files to pipe, no messages     -l  list files (short format)\n",
            "  -f  freshen existing files, create none    -t  test compressed archive data\n",
            "  -u  update files, create if necessary      -z  display archive comment only\n",
            "  -v  list verbosely/show version info       -T  timestamp archive to latest\n",
            "  -x  exclude files that follow (in xlist)   -d  extract files into exdir\n",
            "modifiers:\n",
            "  -n  never overwrite existing files         -q  quiet mode (-qq => quieter)\n",
            "  -o  overwrite files WITHOUT prompting      -a  auto-convert any text files\n",
            "  -j  junk paths (do not make directories)   -aa treat ALL files as text\n",
            "  -U  use escapes for all non-ASCII Unicode  -UU ignore any Unicode fields\n",
            "  -C  match filenames case-insensitively     -L  make (some) names lowercase\n",
            "  -X  restore UID/GID info                   -V  retain VMS version numbers\n",
            "  -K  keep setuid/setgid/tacky permissions   -M  pipe through \"more\" pager\n",
            "  -O CHARSET  specify a character encoding for DOS, Windows and OS/2 archives\n",
            "  -I CHARSET  specify a character encoding for UNIX and other archives\n",
            "\n",
            "See \"unzip -hh\" or unzip.txt for more help.  Examples:\n",
            "  unzip data1 -x joe   => extract all files except joe from zipfile data1.zip\n",
            "  unzip -p foo | more  => send contents of foo.zip via pipe into program more\n",
            "  unzip -fo foo ReadMe => quietly replace existing ReadMe if archive file newer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Download small Test set (this is a small testset just use for reference during training)\n",
        "import gdown\n",
        "file_id = '1-02FPvdTaQFDMatEvXAeKLCmnwW6RLx4' #test_set\n",
        "filename_test = 'test_set.zip'  # Desired file name and extension\n",
        "# Construct the download URL\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "# Download the file\n",
        "gdown.download(url, filename_test, quiet=False)\n",
        "#Unzip\n",
        "!unzip -q $filename_test -d $DATASET_PATH/$TRAIN_SET_PATH/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zY128DjN8xt"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tTnMSRWN8xu",
        "outputId": "e88e14e3-a0a1-426f-eea8-7b02bd1c3965",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "                     arch: res50                         \n",
            "               batch_size: 32                            \t[default: 64]\n",
            "                    beta1: 0.9                           \n",
            "                blur_prob: 0                             \n",
            "                 blur_sig: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                class_bal: False                         \n",
            "                  classes: car,cat,chair,horse           \t[default: ]\n",
            "           continue_train: False                         \n",
            "                 cropSize: 224                           \n",
            "                 data_aug: False                         \n",
            "                 dataroot: datasets/ForenSynths_train    \t[default: ./dataset/]\n",
            "                delr_freq: 5                             \t[default: 20]\n",
            "          earlystop_epoch: 15                            \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                  isTrain: True                          \t[default: None]\n",
            "               jpg_method: cv2                           \n",
            "                 jpg_prob: 0                             \n",
            "                 jpg_qual: 75                            \n",
            "               last_epoch: -1                            \n",
            "                 loadSize: 256                           \n",
            "                loss_freq: 400                           \n",
            "                       lr: 0.0002                        \t[default: 0.0001]\n",
            "                     mode: binary                        \n",
            "                     name: adof-progan-4class-2025_07_12_02_58_48\t[default: experiment_name]\n",
            "                new_optim: False                         \n",
            "                    niter: 30                            \t[default: 1000]\n",
            "                  no_flip: False                         \n",
            "              num_threads: 2                             \t[default: 8]\n",
            "                    optim: adam                          \n",
            "           resize_or_crop: scale_and_crop                \n",
            "                rz_interp: bilinear                      \n",
            "          save_epoch_freq: 20                            \n",
            "         save_latest_freq: 2000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "              train_split: train                         \n",
            "                val_split: val                           \n",
            "----------------- End -------------------\n",
            "train.py  --name  adof-progan-4class-  --dataroot  datasets/ForenSynths_train  --num_thread  2  --classes  car,cat,chair,horse  --batch_size  32  --delr_freq  5  --lr  0.0002  --niter  30\n",
            "*************************\n",
            "2025_07_12_02_58_49\n",
            "(0 progan      ) acc: 50.0; ap: 51.8; r_acc: 1.0; f_acc: 0.0\n",
            "(1 stylegan    ) acc: 50.0; ap: 55.3; r_acc: 1.0; f_acc: 0.0\n",
            "(2 stylegan2   ) acc: 50.0; ap: 64.0; r_acc: 1.0; f_acc: 0.0\n",
            "(3 biggan      ) acc: 50.0; ap: 52.6; r_acc: 1.0; f_acc: 0.0\n",
            "(4 cyclegan    ) acc: 50.0; ap: 43.0; r_acc: 1.0; f_acc: 0.0\n",
            "(5 stargan     ) acc: 50.0; ap: 39.8; r_acc: 1.0; f_acc: 0.0\n",
            "(6 gaugan      ) acc: 50.0; ap: 37.3; r_acc: 1.0; f_acc: 0.0\n",
            "(7 deepfake    ) acc: 50.0; ap: 35.0; r_acc: 1.0; f_acc: 0.0\n",
            "(8 Mean      ) acc: 50.0; ap: 47.4\n",
            "*************************\n",
            "2025_07_12_02_59_57\n",
            "cwd: /content/ADOF\n",
            "2025_07_12_03_01_45 Train loss: 0.31975826621055603 at step: 400 lr 0.0002\n",
            "Saving model ./checkpoints/adof-progan-4class-2025_07_12_02_58_48/model_epoch_0.pth\n",
            "(Val @ epoch 0) acc: 0.89625; ap: 0.9879920365309278\n",
            "*************************\n",
            "2025_07_12_03_03_32\n",
            "(0 progan      ) acc: 89.6; ap: 98.7; r_acc: 1.0; f_acc: 0.8\n",
            "(1 stylegan    ) acc: 86.8; ap: 99.3; r_acc: 1.0; f_acc: 0.7\n",
            "(2 stylegan2   ) acc: 92.2; ap: 99.7; r_acc: 1.0; f_acc: 0.8\n",
            "(3 biggan      ) acc: 74.8; ap: 86.9; r_acc: 0.9; f_acc: 0.6\n",
            "(4 cyclegan    ) acc: 62.4; ap: 84.3; r_acc: 0.9; f_acc: 0.3\n",
            "(5 stargan     ) acc: 75.8; ap: 99.9; r_acc: 1.0; f_acc: 0.5\n",
            "(6 gaugan      ) acc: 54.2; ap: 64.1; r_acc: 0.8; f_acc: 0.2\n",
            "(7 deepfake    ) acc: 52.2; ap: 88.8; r_acc: 1.0; f_acc: 0.0\n",
            "(8 Mean      ) acc: 73.5; ap: 90.2\n",
            "*************************\n",
            "2025_07_12_03_04_46\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ADOF/train.py\", line 102, in <module>\n",
            "    model.optimize_parameters()\n",
            "  File \"/content/ADOF/networks/trainer.py\", line 64, in optimize_parameters\n",
            "    self.loss.backward()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "#experiment-01-no-filter\n",
        "!find $DATASET_PATH -type d -name \"*ipynb*\" -exec rm -r {} +\n",
        "!python train.py \\\n",
        "--name adof-progan-4class- \\\n",
        "--dataroot $DATASET_PATH/$TRAIN_SET_PATH \\\n",
        "--num_thread 2 \\\n",
        "--classes car,cat,chair,horse --batch_size 32 --delr_freq 5 --lr 0.0002 --niter 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW0ofv3qTkZa"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x download_dataset.sh\n",
        "!sed -i 's/\\r$//' download_dataset.sh\n",
        "!./download_dataset.sh"
      ],
      "metadata": {
        "id": "saqC-9xUlXwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wD2QXOfFTjZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06869a0a-285b-4e3b-f8da-3451c134bc8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model_path ./weights/ADOF_model_epoch_9.pth\n",
            "=========================================================\n",
            "                   UniversalFakeDetect\n",
            "=========================================================\n",
            "2025_07_12_03_08_40\n",
            "(0 dalle       ) acc: 90.5; ap: 97.4; r_acc: 0.9; f_acc: 0.9\n",
            "(1 ldm_100     ) acc: 97.1; ap: 99.8; r_acc: 0.9; f_acc: 1.0\n",
            "(2 glide_100_10) acc: 97.0; ap: 99.9; r_acc: 0.9; f_acc: 1.0\n",
            "(3 guided      ) acc: 75.6; ap: 87.4; r_acc: 0.6; f_acc: 0.9\n",
            "(4 glide_100_27) acc: 97.0; ap: 99.9; r_acc: 0.9; f_acc: 1.0\n",
            "(5 ldm_200_cfg ) acc: 96.8; ap: 99.8; r_acc: 0.9; f_acc: 1.0\n",
            "(6 glide_50_27 ) acc: 96.7; ap: 99.8; r_acc: 0.9; f_acc: 1.0\n",
            "(7 ldm_200     ) acc: 97.0; ap: 99.8; r_acc: 0.9; f_acc: 1.0\n",
            "(8 Mean      ) acc: 93.5; ap: 98.0\n",
            "*************************\n"
          ]
        }
      ],
      "source": [
        "# You should update the test set directory in the \"test.py\" file.\n",
        "!find $DATASET_PATH -type d -name \"*ipynb*\" -exec rm -r {} +\n",
        "!python test.py \\\n",
        "--model_path ./weights/ADOF_model_epoch_9.pth  \\\n",
        "--num_thread 2 \\\n",
        "--batch_size 32"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}